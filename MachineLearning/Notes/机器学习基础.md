机器学习基础的学习笔记。



# 1. 基本概念

## 1.1 定义

机器学习算法是一种能够从数据中学习的算法。那么这里的学习的定义是什么呢？这里有一个简单的定义：

> 对于某类任务 T 和性能度量 P，一个计算机程序通过经验 E 改进后，在任务 T 上由性能度量 P 衡量的性能有所提升，这称为学习。

举例来说这个定义，比如对于图像分类这个任务，一般的性能度量 P 就是分类的准确率，而经验 E 其实就是图片数据集，当我们采用的算法，比如 CNN，在给定的训练集上训练后，然后在测试集上的准确率有所提升，这就是学习了。

这里的任务 T、经验 E 和性能 P 其实指代的内容非常的多，这里简单的介绍一下。

首先，对于任务 T，在机器学习领域里，可以是这些方向的任务：

- 分类：在该任务中计算机程序需要判断输入数据是属于给的 k 类中的哪一类，最常见的就是人脸识别，也是图像分类的一个子方向，另外还有语音识别、文本识别等；
- 回归：在该任务中需要对给定的输入预测数值，比如预测房价或者证券未来的价格等；
- 转录：将一些相对非结构化表示的数据，转录为离散的文本形式。比如 OCR（光学字符识别）、语音识别等；
- 机器翻译：将一种语言的序列转化为另一种语言。比如英语翻译为中文；
- 异常检测：查找不正常或者非典型的个体；
- 去噪

- 等等

对于性能度量 P，在不同的任务中会采用不同的性能指标，比如：

- 准确率和错误率
- 召回率、精准率、F1
- ROC 和 AUC
- 均方误差（MSE）、均方根误差（RMSE）
- 交并比 IoU

而经验 E，一般就是指数据集了，不同的任务对数据集的要求也不一样，比如图片分类一般就是图片和图片的标签，但目标检测、图像分割，需要的除了图片、标签，有的还需要图片中物体的标注框或者坐标信息等。



## 1.2 各种常见算法图示

如下图所示，这些是常见的机器学习算法的图示。

|                           回归算法                           |                           聚类算法                           |                          正则化方法                          |
| :----------------------------------------------------------: | :----------------------------------------------------------: | :----------------------------------------------------------: |
| <img src="/Users/luocai/Nutstore Files/Study-Notes/MachineLearning/Notes/images/常见算法图示/1.jpg" style="zoom:24%;" /> | <img src="/Users/luocai/Nutstore Files/Study-Notes/MachineLearning/Notes/images/常见算法图示/2.jpg" style="zoom:24%;" /> | <img src="/Users/luocai/Nutstore Files/Study-Notes/MachineLearning/Notes/images/常见算法图示/3.jpg" style="zoom:24%;" /> |

|                          决策树学习                          |                          贝叶斯方法                          |                         基于核的算法                         |
| :----------------------------------------------------------: | :----------------------------------------------------------: | :----------------------------------------------------------: |
| <img src="/Users/luocai/Nutstore Files/Study-Notes/MachineLearning/Notes/images/常见算法图示/2.2.4.png" style="zoom:25%;" /> | <img src="/Users/luocai/Nutstore Files/Study-Notes/MachineLearning/Notes/images/常见算法图示/5.jpg" style="zoom:25%;" /> | <img src="/Users/luocai/Nutstore Files/Study-Notes/MachineLearning/Notes/images/常见算法图示/6.jpg" style="zoom:25%;" /> |

|                           聚类算法                           |                         关联规则学习                         |                         人工神经网络                         |
| :----------------------------------------------------------: | :----------------------------------------------------------: | :----------------------------------------------------------: |
| <img src="/Users/luocai/Nutstore Files/Study-Notes/MachineLearning/Notes/images/常见算法图示/7.jpg" style="zoom:25%;" /> | <img src="/Users/luocai/Nutstore Files/Study-Notes/MachineLearning/Notes/images/常见算法图示/2.2.8.png" style="zoom:36%;" /> | <img src="/Users/luocai/Nutstore Files/Study-Notes/MachineLearning/Notes/images/常见算法图示/2.2.09.png" style="zoom:36%;" /> |

|                           深度学习                           |                         降低维度算法                         |                           集成算法                           |
| :----------------------------------------------------------: | :----------------------------------------------------------: | :----------------------------------------------------------: |
| <img src="/Users/luocai/Nutstore Files/Study-Notes/MachineLearning/Notes/images/常见算法图示/2.2.10.png" style="zoom:50%;" /> | <img src="/Users/luocai/Nutstore Files/Study-Notes/MachineLearning/Notes/images/常见算法图示/2.2.11.png" style="zoom:36%;" /> | <img src="/Users/luocai/Nutstore Files/Study-Notes/MachineLearning/Notes/images/常见算法图示/2.2.12.png" style="zoom:50%;" /> |



## 1.3 计算图的导数计算

计算图导数计算是反向传播，利用链式法则和隐式函数求导。
	
假设 $z = f(u,v)$ 在点 $(u,v)$ 处偏导连续，$(u,v)$是关于 $t$ 的函数，在 $t$ 点可导，求 $z$ 在 $t$ 点的导数。

根据链式法则有
$$
\frac{dz}{dt}=\frac{\partial z}{\partial u}.\frac{du}{dt}+\frac{\partial z}{\partial v}
				.\frac{dv}{dt}
$$

链式法则用文字描述:“由两个函数凑起来的复合函数，其导数等于里边函数代入外边函数的值之导数，乘以里边函数的导数。 

为了便于理解，下面举例说明：
$$
f(x)=x^2,g(x)=2x+1
$$

则:
$$
{f[g(x)]}'=2[g(x)] \times g'(x)=2[2x+1] \times 2=8x+4
$$

## 1.4 局部最优和全局最优

优化问题一般分为局部最优和全局最优。其中，

1. 局部最优，就是在函数值空间的一个**有限区域内寻找最小值**；而全局最优，是在函数值空间**整个区域寻找最小值**问题。
2. 函数局部最小点是它的函数值小于或等于附近点的点，但是有可能大于较远距离的点。
3. 全局最小点是那种它的函数值小于或等于所有的可行点。



### 1.4.1 如何区分局部最小点和鞍点

参考知乎回答：

- https://www.zhihu.com/question/358632429/answer/919562000

- https://www.zhihu.com/question/68109802/answer/263503269



通常一阶导数为 0 的点称为稳定点，可以分为三类：

- 局部最小点
- 局部最大点
- 鞍点



鞍点如下所示：

<img src="https://gitee.com/lcai013/image_cdn/raw/master/notes_images/%E9%9E%8D%E7%82%B9%E5%9B%BE%E7%A4%BA.png" style="zoom:50%;" />

一般区分鞍点和局部最优的方法是使用神经网络 loss surface 的 Hessian 矩阵，通过计算 Hessian 矩阵的特征值，进行判断：

- 当 Hessian 矩阵的**特征值有正有负**的时候，神经网络的一阶导数为 0 的点是**鞍点**；
- 当 Hessian 矩阵的**特征值是非负**的时候，神经网络的一阶导数为 0 的点是**局部极小值点**；
- 当 Hessian 矩阵**最小特征值小于零**，则为**严格鞍点**（包含了局部最大）



根据文章：[Geometry of Neural Network Loss Surfaces via Random Matrix Theory](https://link.zhihu.com/?target=http%3A//proceedings.mlr.press/v70/pennington17a/pennington17a.pdf)，可以看到神经网络的 Hessian 矩阵的特征值分布如下:

<img src="https://gitee.com/lcai013/image_cdn/raw/master/notes_images/Geometry%20of%20Neural%20Networks.png" style="zoom:100%;" />

其中 $\phi$ 表示参数数目和数据量之比，其值越大表示数量相对较少，$\lambda$ 是特征值，$\epsilon$ 表示 loss 值，所以从上图可以得到：

- 当 loss 很大的时候，特征值有正有负，**表明鞍点是困扰优化的主要原因**；
- 当 loss 很小的时候，特征值慢慢都是非负数，**也就是说这个时候基本是局部最小点**。



另外一种判断是否是鞍点的方法：**若某个一阶导数为0的点在至少一个方向上的二阶导数小于0，那它就是鞍点**。

最优点和鞍点的区别在于**其在各个维度是否都是最低点**。

只要某个一阶导数为0的点在某个维度上是最高点而不是最低点，那它就是鞍点。**而区分最高点和最低点当然就是用二阶导数**，斜率从负变正的过程当然就是“下凸”，即斜率的导数大于0，即二阶导数大于0。反之则为“上凹”，二阶导数小于0。





### 1.4.2 如何避免陷入局部最小值或者鞍点

实际上，我们并不需要害怕陷入局部最小值，原因有这几个：

- 第一个，很直观的解释来自于上面特征值的分布信息：当loss很小的时候，我们才会遇到局部最小值问题，**也就是说这时候的loss已经足够小，我们对这时候的loss已经足够满意了，不太需要花更大力气去找全局最优值**。

- 第二个，**在一定假设条件下，很多研究表明深度学习中局部最小值很接近于全局最小值**。

另外，根据https://www.zhihu.com/question/68109802的回答：

> 实际上我们可能并没有找到过”局部最优“，更别说全局最优了；
>
> ”局部最优是神经网络优化的主要难点“，这其实是来自于一维优化问题的直观想象，单变量的情况下，优化问题最直观的困难就是有很多局部极值。但在多变量的情况下，就不一定能找到局部最优了；





而对于鞍点，逃离鞍点的做法有这几种：

1. 利用严格鞍点负特征值对应的方向，采用矩阵向量乘积的形式找到下降方向；
2. 利用扰动梯度方法逃离鞍点，在梯度的模小于某个数的时候，在梯度上加个动量。





## 1.5 机器学习、深度学习、数据挖掘、大数据之间的关系

首先来看这四者简单的定义：

- **大数据**通常被定义为“超出常用软件工具捕获，管理和处理能力”的数据集，一般是在数据量、数据速度和数据类别三个维度上都大的问题。 
- **机器学习**关心的问题是如何构建计算机程序使用经验自动改进。
- **数据挖掘**是从数据中提取模式的特定算法的应用，在数据挖掘中，重点在于算法的应用，而不是算法本身。
- **深度学习**是机器学习的一个子类，一般特指学习层数较高的网络结构，这个结构通常会结合线性和非线性的关系。

关于这四个的关系，可以如下图所示：

<img src="https://gitee.com/lcai013/image_cdn/raw/master/notes_images/%E5%A4%A7%E6%95%B0%E6%8D%AE%E3%80%81%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%81%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%B3%E7%B3%BB%E5%9B%BE.jpg" style="zoom:50%;" />



**机器学习和数据挖掘**之间的关系如下：

> 数据挖掘是一个过程，在此过程中机器学习算法被用作提取数据集中的潜在有价值模式的工具。



大数据与深度学习关系总结如下：

（1）**深度学习是一种模拟大脑的行为**。可以从所学习对象的机制以及行为等等很多相关联的方面进行学习，模仿类型行为以及思维。

（2）**深度学习对于大数据的发展有帮助**。深度学习对于大数据技术开发的每一个阶段均有帮助，不管是数据的分析还是挖掘还是建模，只有深度学习，这些工作才会有可能一一得到实现。

（3）**深度学习转变了解决问题的思维**。很多时候发现问题到解决问题，走一步看一步不是一个主要的解决问题的方式了，在深度学习的基础上，要求我们从开始到最后都要基于一个目标，为了需要优化的那个最终目标去进行处理数据以及将数据放入到数据应用平台上去，这就是端到端（End to End）。

（4）**大数据的深度学习需要一个框架**。在大数据方面的深度学习都是从基础的角度出发的，深度学习需要一个框架或者一个系统。总而言之，将你的大数据通过深度分析变为现实，这就是深度学习和大数据的最直接关系。



机器学习和深度学习的关系：

- 深度学习是机器学习的一个子类，是机器学习的一类算法，相比传统的机器学习方法，深度学习有这几个特点：
  - **对硬件要求更高**。经常需要 GPU 才能快速完成任务，单纯用 CPU 执行任务，那耗时是非常的惊人；
  - **对数据量要求更高**。传统的机器学习一般可能只需要几百上千的数据量，但是对于深度学习的任务，至少也需要上万甚至几百万数据量，否则很容易过拟合；
  - **具有更强的特征提取能力**。深度学习可以从数据中学习到不同等级的特征，从低级的边缘特征，到高级的语义特征，这也是越来越多的机器学习方向都采用深度学习算法来解决问题的一个原因，性能更加强；
  - **可解释性差**。因为抽象层次较高，所以深度学习也经常被称为是一个黑匣子。
- 机器学习的核心是数学，是用一个数学模型，然后输入数据来调节数学模型的参数，从而让数学模型可以解决特定的某类问题。简单说就是希望训练得到一个可以解决特定问题的数学函数。



## 1.6 为什么要使用机器学习

原因如下：

- 需要进行大量手工调整或需要拥有长串规则才能解决的问题：机器学习算法通常可以**简化代码、提高性能**。
- 问题复杂，传统方法难以解决：最好的机器学习方法可以找到解决方案。
- 环境有波动：机器学习算法可以**适应新数据**。
- 洞察复杂问题和大量数据


一些机器学习的应用例子：

- 数据挖掘
- 一些无法通过手动编程来编写的应用：如自然语言处理，计算机视觉
- 一些自助式的程序：如推荐系统
- 理解人类是如何学习的





# 2. 机器学习系统的类型

机器学习有多种类型，可以根据如下规则进行分类：

- 是否在人类监督下进行训练（监督，非监督，半监督和强化学习）
- 是否可以动态渐进学习（在线学习 vs批量学习）
- 它们是否只是通过简单地比较新的数据点和已知的数据点，或者在训练数据中进行模式识别，以建立一个预测模型，就像科学家所做的那样（基于实例学习 vs基于模型学习）



## 2.1 是否有监督

第一种分类机器学习的方法是可以根据训练时监督的量和类型进行分类。主要有四类：监督学习、非监督学习、半监督学习和强化学习。

### 2.1.1 监督学习

监督学习，顾名思义就是带有监督的学习，**而监督就是体现在训练数据都是有标签的**，所有在训练模型的时候可以根据数据的真实标签不断调整模型，从而得到一个性能更好的模型。

监督学习主要有两个常见的典型的任务--**分类和回归**。

#### 分类

分类问题主要就是预测新数据的类别问题。例如上文提到的垃圾邮件过滤器就是一个二分类问题，将邮件分为垃圾邮件还是正常的邮件，如下图所示。

![](https://gitee.com/lcai013/image_cdn/raw/master/notes_images/%E5%88%86%E7%B1%BB%E7%A4%BA%E4%BE%8B.png)





#### 回归

回归问题主要是预测目标数值。比如给定预测房价的问题，给定一些特征，如房子大小、房间数量、地理位置等等，然后预测房子的价格。如下图所示：

![](https://gitee.com/lcai013/image_cdn/raw/master/notes_images/%E5%9B%9E%E5%BD%92%E7%A4%BA%E4%BE%8B.png)

注意，一些回归算法也可以用来进行分类，反之亦然。例如，逻辑回归通常用来进行分类，它可以生成一属于每个类别的概率值，然后选择最大概率的类别作为预测的类别。

常用的监督学习算法有：

- K近邻算法
- 线性回归
- 逻辑回归
- 支持向量机（SVM）
- 决策树和随机森林
- 深度学习方法



### 2.1.2 非监督学习

和监督学习相反，非监督学习就是采用没有标签的数据集。

非监督主要有四个典型的任务，分别是聚类、降维、异常检测和关联规则学习。



#### 聚类

聚类就是将数据根据一定的规则分成多个类，通常是采用相似性。比如对于博客访客的聚类，通过聚类算法，检测相似性访客的分组，如下图所示。不需要告诉算法访客是哪个类别，它会自动根据访客的属性找到相互间的关系，比如它可能找出访客的职业关系，将访客分为有 40% 的是上班族，有 50% 的是学生，或者对于技术博客，可能就是根据开发方向，划分为前端、后台、移动开发、人工智能等等。甚至，如果采用层次聚类分析算法，还可以继续对上述的分类进行更加详细的划分。这种做法可以帮助博主知道自己博客的主要群体是谁，更好规划自己博客发表的文章应该以什么方向为主。

![](https://gitee.com/lcai013/image_cdn/raw/master/notes_images/cluster_example.png)

可视化算法也是极佳的非监督学习案例：**给算法大量复杂的且不加标签的数据，算法输出数据的2D或3D图像**。如下图所示，算法会试图保留数据的结构（即尝试保留输入的独立聚类，避免在图像中重叠），这样就可以明白数据是如何组织起来的，也许还能发现隐藏的规律。

![](https://gitee.com/lcai013/image_cdn/raw/master/notes_images/visualize_example.png)

#### 降维

**降维的目的是简化数据、但是不能失去大部分信息**。做法之一是**合并若干相关的特征**。例如，汽车的里程数与车龄高度相关，降维算法就会将它们合并成一个，表示汽车的磨损。这叫做特征提取。

此外，在采用机器学习算法训练的时候，可以对训练集进行降维，这样有助于提高训练速度，降低占用的硬盘和内存空间，有时候也能提高算法的性能，但必须选择合适的降维算法，否则性能实际上是很有可能会下降的。



#### 异常检测

另一个重要的非监督任务是异常检测（anomaly detection）。例如，检测异常的信用卡转账以防欺诈，检测制造缺陷，或者在训练之前自动从训练数据集去除异常值。异常检测的系统使用正常值训练的，当它碰到一个新实例，它可以判断这个新实例是像正常值还是异常值。

![](https://gitee.com/lcai013/image_cdn/raw/master/notes_images/anomaly%20detection.png)

#### 关联规则学习

最后，另一个常见的非监督任务是关联规则学习，它的目标是挖掘大量数据以发现属性间有趣的关系。例如，假设你拥有一个超市。在销售日志上运行关联规则，可能发现买了烧烤酱和薯片的人也会买牛排。因此，你可以将这些商品放在一起。




下面是一些最重要的非监督学习算法：

1. 聚类
    - K 均值（k-means）
    - 层次聚类分析（Hierarchical Cluster Analysis, HCA）
    - 期望最大值
2. 可视化和降维
    - 主成分分析（Principal	Component Analysis, PCA）
    - 核主成分分析
    - 局部线性嵌入（Locally-Linear Embedding, LLE）
    - t-分布邻域嵌入算法（t-distributed Stochastic Neighbor Embedding, t-SNE）
3. 关联性规则学习
    - Apriori 算法
    - Eclat算法





### 2.1.3 半监督学习

一些算法可以处理部分带标签的训练数据，通常是大量不带标签数据加上小部分带标签数据。这称作半监督学习。如下图所示，图中灰色圆点表示没有标签的数据，仅有几个三角形和正方形点表示带标签的数据。

![](https://gitee.com/lcai013/image_cdn/raw/master/notes_images/semi-supriviesed_learning.png)

**多数半监督学习算法是非监督和监督算法的结合**。

例如，深度信念网络（deep belief networks）是基于被称为互相叠加的受限玻尔兹曼机（restricted Boltzmann machines，RBM）的非监督组件。RBM 是先用非监督方法进行训练，再用监督学习方法进行整个系统微调。

半监督学习的示例，如一些图片存储服务，比如 Google Photos，是半监督学习的好例子。一旦你上传了所有家庭相片，它就能自动识别相同的人 A 出现了相片1、5、11	中，另一个人	B 出现在了相片 2、5、7 中。这是算法的非监督部分（聚类）。现在系统需要的就是你告诉这两个人是谁。只要给每个人一个标签，算法就可以命名每张照片中的每个人，特别适合搜索照片。



常见应用场景：应用场景包括分类和回归，算法包括一些对常用监督式学习算法的延伸，通过对已标记数据建模，在此基础上，对未标记数据进行预测。



算法举例：常见算法如图论推理算法（Graph Inference）或者拉普拉斯支持向量机（Laplacian SVM）等。





### 2.1.4 强化学习

强化学习和上述三种学习问题是非常不同的。学习系统在这里被称为**智能体**（ agent），可以对环境进行观察，选择和执行动作，获得**奖励**（负奖励是惩罚，见下图）。然后它必须自己学习哪个是最佳方法（称为**策略**，policy），以得到长久的最大奖励。策略决定了智能体在给定情况下应该采取的行动 。

![](https://gitee.com/lcai013/image_cdn/raw/master/notes_images/Reinforcement_learning.png)



目前强化学习的应用还不算非常广，特别是结合了深度学习的强化学习，主要是应用在机器人方面，当然最著名的一个应用就是 DeepMind 的 AlphaGo 了，它是通过分析数百万盘棋局学习制胜策略，然后自己和自己下棋。要注意，在比赛中机器学习是关闭的；AlphaGo	只是使用它学会的策略。 



## 2.2 是否可以动态渐进学习

第二种分类机器学习的准则是，它是否能从导入的数据流进行持续学习。也就是如果导入的是持续的数据流，机器学习算法能否在不断采用新数据来训练已经训练好的模型，并且新的模型对新旧数据都还有很好的性能。



### 2.2.1 批量学习

在批量学习中，**系统不能进行持续学习：必须用所有可用数据进行训练**。这通常会占用大量时间和计算资源，所以一般是线下做的。

首先是进行训练，然后部署在生产环境且停止学习，它只是使用已经学到的策略。**这称为离线学习**。

对于批量学习算法来说，当获取到新数据的时候，就需要重新重头训练整个数据集，然后更新模型，如果是应用该算法系统，那就相当于需要更新系统，需要停掉旧版本的系统，重新上线新版本的系统。

当然，一般训练、评估、部署一套机器学习的系统的整个过程可以自动进行，所以即便是批量学习也可以适应改变。只要有需要，就可以方便地更新数据、训练一个新版本。并且对于更新周期，可以选择每 24 小时或者每周更新一次。

但是，批量学习还是存在下面的缺点：

1. **实时性差**，即对于需要快速适应变化的系统，比如预测股票变化、电商推荐系统等，就不适合采用批量学习算法；
2. **耗费大量计算资源**，用全部数据训练需要大量计算资源（CPU、内存空间、磁盘空间、磁盘 I/O、网络 I/O 等等），特别是训练集特别大的情况，更加凸显这个问题的严峻性；
3. **无法应用在资源有限的设备上**，比如需要自动学习的系统，但是如果采用智能手机，每次采用大量训练数据重新训练几个小时是非常不实际的。



### 2.2.2 在线学习

批量学习的缺陷和问题可以通过采用在线学习算法来解决。

在在线学习中，是用数据实例持续地进行训练，可以一次一个或一次几个实例（称为小批量）。每个学习步骤都很快且廉价，所以系统可以动态地学习到达的新数据。

在线学习虽然名字带着在线两个字，但是实际上它的训练过程也是离线的，因此应该说是持续学习或者增量学习。

在线学习有下面几个优点：

1. **实时性好**。在线学习算法非常适合接收连续流的数据，然后自动更新模型，实时性比批量学习更好；
2. **可以节省大量计算资源**。在线学习算法在学习新数据后，可以扔掉训练数据，从而节省大量存储空间；此外，训练得过程不需要加载所有训练数据，对于内存、CPU 等资源的要求也大大减少；
3. **实现核外学习**(out-of-core learning)。当内存不足以加载训练集的时候，可以采用在线学习算法多次训练，每次加载一部分训练集，即将一部分训练集当做新数据不断加载，直到训练完所有数据。

在线学习也存在两个挑战：

1. **学习速率问题**。学习速率是在线学习的一个重要参数，它反映了在线学习算法有多快地适应数据的改变，必须选择一个合适的学习速率，因为学习速率过大，系统可以很快适应新数据，但是也容易遗忘旧数据，比如图像分类问题，训练了一个 50 类分类器后，增加新的 10 类数据，一旦学习速率过快，系统只会记住新的 10 个类别，忘记了前面的 50 个类别的数据。相反的，如果你设定的学习速率低，系统的惰性就会强：即，它学的更慢，但对新数据中的噪声或没有代表性的数据点结果不那么敏感。
2. **坏数据的影响**。如果采用坏数据训练，会破坏系统的性能。要减小这种风险，你需要密集监测，如果检测到性能下降，要快速关闭（或是滚回到一个之前的状态）。你可能还要监测输入数据，对反常数据做出反应（比如，使用异常检测算法）。



## 2.3 实例学习 vs 模型学习

第三种分类机器学习的方法是判断它们是如何进行归纳推广的。大多机器学习任务是关于预测的。这意味着给定一定数量的训练样本，系统需要能推广到之前没见到过的样本。对训练数据集有很好的性能还不够，真正的目标是对新实例预测的性能。

有两种主要的归纳方法：基于实例学习和基于模型学习。

### 2.3.1 实例学习

基于实例学习是**系统先用记忆学习案例，然后使用相似度测量推广到新的例子**，如下图所示：

![](https://gitee.com/lcai013/image_cdn/raw/master/notes_images/BaseOnInstanceLearning.png)

这种学习算法可以说是机器学习中最简单的算法了，**它实际上就是采用存储的数据集进行分类或者回归**。

**典型的算法就是 KNN 算法**，即 K 近邻算法，它就是将新的输入数据和已经保存的训练数据采用相似性度量（一般采用欧式距离）得到最近的 K 个训练样本，并采用 K 个训练样本中类别出现次数最多的类别作为预测的结果。

所以，这种算法的缺点就比较明显了：

- **对存储空间的需求很大**，需要占用的空间直接取决于实例数量的大小；
- **运行时间比较慢**，因为需要需要与已知的实例进行比对。



### 2.3.2 模型学习

和基于实例学习相反的就是基于模型学习：建立这些样本的模型，然后使用这个模型进行预测。如下图所示：

![](https://gitee.com/lcai013/image_cdn/raw/master/notes_images/BaseOnModelLearning.png)


基于模型学习算法的流程一般如下所示：

- 研究数据。先对数据进行分析，这可能包含清洗数据、特征筛选、特征组合等等
- 选择模型。选择合适的模型，从简单的线性回归、逻辑回归，到慢慢复杂的随机森林、集成学习，甚至深度学习的卷积神经网络模型等等
- 用训练数据进行训练。也就是寻找最适合算法模型的参数，使得代价函数取得最小值。
- 使用模型对新案例进行预测（这称作推断）。预测结果非常好，就能上线系统；如果不好，就需要进行错误分析，问题出现在哪里，是数据问题还是模型问题，找到问题，然后继续重复这个流程。





# 3. 如何构建一个机器学习项目

一般我们构建一个机器学习项目，常用的还是监督学习的算法，所以这里按照监督学习算法来简单说明如何构造一个机器学习项目。

通常的步骤是这样的：

1.	 **项目概述**。明确项目的目标，需要用什么性能度量，然后确定问题的类别（监督学习、非监督学习或者需要批量学习还是在线学习方法），大概确定采用的算法；
2.	 **获取数据**。获取公开的相关领域的数据集，准备开发环境，测试集一般就是采用特定的数据集，比如业务给出的实际应用场景的数据。
3.	 **发现并可视化数据，发现规律**。对数据进行探索，查找数据间存在的一些关联和规律。
4.	 **为机器学习算法准备数据**。这一步其实就是做好特征工程，对原始数据进行预处理、特征提取、特征选择等步骤。
5.	 **模型训练**。选择好合适的机器学习模型，然后进行训练，通常可能会考虑选择多个模型进行对比，然后挑选合适的算法模型。
6.	 **微调模型**。对选择好的模型进行调参，尽量得到最佳的性能。
7.	 **给出解决方案**。这一步主要是展示给你的上级，你要采用什么算法模型，实验结果如何等等。
8.	 **部署、监控、维护系统**。最后就是部署模型，上线，然后监控服务的运行，并进行维护。

  

# 4. 机器学习的主要挑战

在介绍基于模型学习算法的流程的时候，对于预测结果不好的问题分析，主要说了是数据问题还是模型问题，这同时也就是机器学习的效果不好的两个主要原因，即错误的数据和错误的算法。

## 4.1 训练数据量不足

第一个问题就是**训练数据的数量问题**，这是非常重要的问题。

因为即使是简单的问题，一般也需要数千的样本，这还是因为简单的问题一般采用简单的算法就可以解决，对于复杂的图像或语音问题，通常需要数百万的样本，特别是如果采用现在非常热门的深度学习算法，比如卷积神经网络模型，这些复杂的模型如果没有足够的数据量支持，非常容易陷入过拟合的情况。

实际上更多数量的训练集也是为了获得更有代表性的数据，能够学习到这类数据的所有特征。

但是，应该注意到，**小型和中型的数据集仍然是非常常见的，获得额外的训练数据并不总是轻易和廉价的，所以不要抛弃算法**。



## 4.2 没有代表性的训练数据

无论采用基于实例还是基于模型的学习，让训练数据对新数据具有代表性是非常重要的。如果训练集没有代表性，那么训练得到的模型就是不可能得到准确性的模型，比如人脸识别中，模型没有学习到某个人最明显的代表性的特征，比如高鼻梁或者没有眉毛等突出特征，那么模型对这个人的识别率就不会很高。

使用具有代表性的训练集对于推广到新案例是非常重要的。但是做起来比说起来要难：**如果样本太小，就会有样本噪声（即会有一定概率包含没有代表性的数据），但是即使是非常大的样本也可能没有代表性，如果取样方法错误的话。这叫做样本偏差。**




## 4.3 低质量的数据

低质量的数据指的是**数据有错误、带有过多噪声或者是出现异常值等的数据，这种数据会影响系统整体的性能**，因此，**数据清洗**对于构建一个机器学习系统或者一个机器学习项目来说都是必不可少的步骤。

对于这些低质量的数据，通常可以按照如下做法处理：

- 如果一些实例是明显的异常值，最好删掉它们或尝试手工修改错误；
- 如果一些实例缺少特征（比如，你的 5% 的顾客没有说明年龄），你必须决定是否忽略这个属性、忽略这些实例、填入缺失值（比如，年龄中位数），或者训练一个含有这个特征的模型和一个不含有这个特征的模型，等等。



## 4.4 不相关的特征

不相关的特征对于整个机器学习系统是有着反作用的效果，训练数据必须包含足够多的相关特征且非相关特征不多的情况下，才能训练出一个性能不错的模型。机器学习项目成功的关键之一是用好的特征进行训练。这个过程称作**特征工程**，包括：

- 特征选择：在所有存在的特征中选取最有用的特征进行训练。
- 特征提取：组合存在的特征，生成一个更有用的特征（如前面看到的，可以使用降维算法）。
- 收集新数据创建新特征。



## 4.5 过拟合

上述四种情况都是坏数据的情况，接下来是两种算法问题，也是机器学习最常见的两种算法方面的问题，**过拟合和欠拟合**。

**过拟合就是指算法模型在训练集上的性能非常好，但是泛化能力很差，即在测试集上的效果却很糟糕的情况**。比如下图，采用一个高阶多项式回归模型来预测生活满意度和人均 GDP 的关系，很明显看出来，这个模型过拟合了训练数据，其预测效果并不会达到在训练数据上这么好的效果。

![](https://gitee.com/lcai013/image_cdn/raw/master/notes_images/OverfittingExample.png)

通常对于比较复杂的模型，比如深度神经网络，它能够检测和识别到数据中比较细微的规律和特征，但是如果训练集包含噪声，或者训练集数量太少（数量太少会引入样本噪声），这种情况下，模型同样会学习这种噪声，从而导致模型的泛化能力的下降。

一般解决过拟合的方法有：

- 简化模型，这包括了采用简单点的模型、减少特征数量以及限制模型，即采用正则化；
- 增加训练数据
- 减小训练数据的噪声，即数据清洗，比如修正数据错误和去除异常值等

其中**正则化方法是比较常用的方法，它的作用就是限制模型，不让模型过于复杂，从而降低过拟合的风险或者是缓和过拟合的程度**。常用的正则化方法是 **L2 和 L1 正则化**。正则化方法通常会采用一个超参数来控制其限制模型的强度。超参数是一个学习算法的参数（而不是模型的）。这样，它是不会被学习算法本身影响的，它优于训练，在训练中是保持不变的。如何调节超参数也是构建一个机器学习算法模型非常重要的一个步骤，也是让性能能够进一步提升的做法。



## 4.6 欠拟合

欠拟合和过拟合刚好相反，**它就是模型的性能非常差，在训练数据和测试数据上的性能都不好。**

通常也是因为模型过于简单，没有能够很好学习到数据的有效的相关的特征，解决方法有：

- 选择一个更强大的模型，带有更多参数
- 用更好的特征训练学习算法（特征工程）
- 减小对模型的限制（比如，减小正则化超参数）



# 5. 常用的分类算法优缺点

这里给出常用的分类算法的优缺点：

|            算法             | 优点                                                         | 缺点                                                         |
| :-------------------------: | :----------------------------------------------------------- | :----------------------------------------------------------- |
|          线性回归           | 1. 结果易于理解；<br/>2. 容易实现，计算不复杂                | 对非线性数据的拟合效果不好                                   |
| Logistic Regression逻辑回归 | 1. 速度快。<br />2. 简单易于理解，直接看到各个特征的权重。<br />3. 能容易地更新模型吸收新的数据。<br />4. 如果想要一个概率框架，动态调整分类阀值。<br/>5. 实现简单，广泛应用于工业问题上 | 1. 特征处理复杂。<br/>2. 只能处理二分类问题（需要 softmax 才可以处理多分类），且必须线性可分。<br />3. 容易欠拟合，一般准确率不太高。<br />4. 不能很好处理大量多类特征或者变量。<br />5. 特征空间很大时，性能一般。 |
|     Decision Tree决策树     | 1. 不需要任何领域知识或参数假设。<br />2. 适合高维数据。<br />3. 可解释性强，简单易于理解。<br />4. 效率高，短时间内可以处理大量数据，得到可行且效果较好的结果。<br />5. 能够同时处理数据型和常规性属性。 | 1. 对于各类别样本数量不一致数据，信息增益偏向于那些具有更多数值的特征。<br />2. 易于过拟合。<br />3. 忽略属性之间的相关性。<br />4. 不支持在线学习。<br />5. 单棵决策树分类能力弱，并且对连续值变量难以处理。 |
|    随机森林 RandomForest    | 1. 在数据集上表现良好，在当前的很多数据集上，相对其他算法有着很大的优势。<br  /> 2. 它能够处理很高维度（特征很多）的数据，并且不用做特征选择。<br />3. 可以评估特征的重要性<br  />4. 在创建随机森林的时候，对 generlization error 使用的是无偏估计<br  />5. 训练速度快，容易做成并行化方法<br  />6. 在训练过程中，能够检测到特征间的互相影响 <br  />7. 实现比较简单<br  />8. 对于不平衡的数据集来说，它可以平衡误差<br  /> 9. 可以应用在特征缺失的数据集上，并仍然有不错的性能 | 1. 随机森林已经被证明在某些**噪音较大**的分类或回归问题上会过拟合。<br />2. 对于有不同取值的属性的数据，**取值划分较多的属性会对随机森林产生更大的影响**，所以随机森林在这种数据上产出的属性权值是不可信的。 |
|        SVM支持向量机        | 1. 可以解决小样本下机器学习的问题。<br />2. 提高泛化性能。<br />3. 可以解决高维、非线性问题。超高维文本分类仍受欢迎。<br />4. 避免神经网络结构选择和局部极小的问题。 | 1. 对缺失数据或者噪音敏感。<br />2. 内存消耗大，难以解释。<br />3. 运行和调参略烦人。<br />4. 对大规模数据训练比较困难。<br />5. 无法直接支持多分类，但可以通过间接的方法来实现。 |
|     Bayes 贝叶斯分类法      | 1. 所需估计的参数少，对于缺失数据不敏感。<br />2.有着坚实的数学基础，以及稳定的分类效率。 | 1. 需要假设属性之间相互独立，这往往并不成立。（喜欢吃番茄、鸡蛋，却不喜欢吃番茄炒蛋）。<br />2. 需要知道先验概率。<br />3. 分类决策存在错误率。 |
|          KNN K近邻          | 1. 思想简单，理论成熟，既可以用来做分类也可以用来做回归； <br />2. 可用于非线性分类；<br />3.训练时间复杂度为O(n)； <br />4. 准确度高，对数据没有假设，对outlier不敏感； | 1. 计算量太大。<br />2. 对于样本分类不均衡的问题，会产生误判。<br />3. 需要大量的内存。<br />4. 输出的可解释性不强。 |
|   Neural Network 神经网络   | 1. 分类准确率高。<br />2. 并行处理能力强。<br />3. 分布式存储和学习能力强。<br />4. 鲁棒性较强，不易受噪声影响。 | 1. 需要大量参数（网络拓扑、阀值、阈值）。<br />2. 结果难以解释。<br />3. 训练时间过长。 |
|         Adaboosting         | 1. adaboost是一种有很高精度的分类器。<br />2. 可以使用各种方法构建子分类器，Adaboost算法提供的是框架。<br />3. 当使用简单分类器时，计算出的结果是可以理解的。而且弱分类器构造极其简单。<br />4. 简单，不用做特征筛选。<br />5. 不用担心overfitting。 | 对outlier比较敏感                                            |
|            GDBT             | 1. 精度高。<br />2. 能处理非线性数据和多特征类型数据。<br /> 3. 适合低维稠密数据。<br /> 4. 可解释性好。<br /> 5. 不需要对特征做归一化，可以自动选择特征。<br /> 6.能采用多少损失函数，比如均方误差和 LogLoss 等 | 1. boosting 是个串行过程，并行比较麻烦，需要考虑上下树之间的关系。<br /> 2. 计算复杂度高。<br /> 3. 不适合高位稀疏数据。 |



# 6. 目标函数、代价函数、损失函数

参考：

-  https://www.zhihu.com/question/358635266/answer/917582302
- https://zhuanlan.zhihu.com/p/58883095
- https://mp.weixin.qq.com/s/bsfYCaOKHNsbRcH83970fQ



## 6.1 目标函数、代价函数、损失函数的定义

**损失函数（Loss Function）**：针对单个样本，**衡量单个样**本的预测值 ![[公式]](https://www.zhihu.com/equation?tex=%5Chat%7By%7D%5E%7B%28i%29%7D) 与真实值 ![[公式]](https://www.zhihu.com/equation?tex=y%5E%7B%28i%29%7D) 之间的差距。

用来衡量算法的运行情况，估量模型的预测值与真实值的不一致程度，是一个非负实值函数，通常使用$
L(Y, f(x))$来表示。

损失函数越小，模型的鲁棒性就越好。损失函数是经验风险函数的核心部分，也是结构风险函数重要组成部分。

**损失函数**分为**经验风险损失函数**和**结构风险损失函数**。经验风险损失函数指预测结果和实际结果的差别，结构风险损失函数是指经验风险损失函数加上正则项。



**代价函数/成本函数（Cost Function）**：针对多个样本，**衡量多个样本**的预测值 ![[公式]](https://www.zhihu.com/equation?tex=%5Csum_%7Bi%3D1%7D%5E%7Bn%7D+%5Chat%7By%7D%5E%7B%28i%29%7D) 与真实值 ![[公式]](https://www.zhihu.com/equation?tex=%5Csum_%7Bi%3D1%7D%5E%7Bn%7Dy%5E%7B%28i%29%7D) 之间的差距。为什么用代价函数呢，这有两个原因：

1. 为了得到训练逻辑回归模型的参数，需要一个代价函数，通过训练代价函数来得到参数。
2. 用于找到最优解的目的函数。



**目标函数（Objective Function）：**梯度下降等优化算法就是针对目标函数来进行的。其实代价函数就可以是一种目标函数，换句话说，目标函数可以直接选用代价函数。但是，我们经常给代价函数添加一个正则化项，最终作为模型的目标函数。

一般设计的目标函数要有一个下界，在优化过程当中，如果优化算法能够使目标函数不断减小，根据单调有界准则，这个优化算法就能证明是收敛有效的。而代价函数非负更为方便。







## 6.2 常见的损失函数

### 6.2.1 平方损失函数(quadratic)

平方损失函数的公式如下所示：
$$
L(Y, f(x)) = \sum_N (Y-f(x))^2
$$

其中 Y 表示真实标签，f(x) 表示输出值。

一般常用于回归问题。



### 6.2.2 0-1 损失函数

如果预测值和目标值相等，值为0，如果不相等，值为1。
$$
L(Y, f(x)) =
\begin{cases}
1,& Y\ne f(x)\\
0,& Y = f(x)
\end{cases}
$$

特点：

1. 0-1损失函数直接对应分类判断错误的个数，但是它是一个非凸函数，不太适用；

2.  **感知机**就是用的这种损失函数。但是相等这个条件太过严格，因此可以放宽条件，即满足 ![[公式]](https://www.zhihu.com/equation?tex=%7CY+-+f%28x%29%7C+%3C+T) 时认为相等：

$$
L(Y, f(x)) =
\begin{cases}
1,& |Y-f(x)|\geqslant T\\
0,& |Y-f(x)|< T
\end{cases}
$$





### 6.2.3 绝对值损失函数

和0-1损失函数相似，绝对值损失函数表示为：
$$
L(Y, f(x)) = |Y-f(x)|
$$



### 6.2.4 对数损失函数

公式如下所示：
$$
L(Y, P(Y|X)) = -\log{P(Y|X)}=-\frac{1}{N}\sum_{i=1}^N\sum_{j=1}^M y_{ij}log(p_{ij})
$$

其中, Y 为输出变量, X为输入变量, L 为损失函数. N为输入样本量, M为可能的类别数, $y_{ij}$ 是一个二值指标, 表示类别 j 是否是输入实例 xi 的真实类别. $p_{ij}$ 为模型或分类器预测输入实例 xi 属于类别 j 的概率.

**常见的逻辑回归使用的就是对数损失函数**。逻辑回归它假设样本服从伯努利分布（0-1分布），进而求得满足该分布的似然函数，接着取对数求极值等。

逻辑回归推导出的**经验风险函数是最小化负的似然函数**，从损失函数的角度看，就是对数损失函数。**形式上等价于二分类的交叉熵损失函数**。



### 6.2.5 指数损失函数
指数损失函数的标准形式为：
$$
L(Y, f(x)) = \exp(-yf(x))
$$

对离群点、噪声非常敏感。经常用在AdaBoost算法中。



### 6.2.6 Hinge损失函数

Hinge损失函数的标准形式如下：
$$
L(y) = \max{(0, 1-ty)}
$$

统一的形式：
$$
L(Y, f(x)) = \max{(0, Yf(x))}
$$

其中y是预测值，范围为(-1,1)，t为目标值，其为-1或1。

特点：

(1)hinge损失函数表示如果被分类正确，损失为0，否则损失就为 ![[公式]](https://www.zhihu.com/equation?tex=1-yf%28x%29) 。**SVM**就是使用这个损失函数。

(2)一般的 ![[公式]](https://www.zhihu.com/equation?tex=f%28x%29) 是预测值，在-1到1之间， ![[公式]](https://www.zhihu.com/equation?tex=y) 是目标值(-1或1)。其含义是， ![[公式]](https://www.zhihu.com/equation?tex=f%28x%29+) 的值在-1和+1之间就可以了，并不鼓励 ![[公式]](https://www.zhihu.com/equation?tex=%7Cf%28x%29%7C+%3E+1) ，即并不鼓励分类器过度自信，让某个正确分类的样本距离分割线超过1并不会有任何奖励，从而**使分类器可以更专注于整体的误差。**

(3) **健壮性相对较高，对异常点、噪声不敏感，但它没太好的概率解释**。



在线性支持向量机中，最优化问题可等价于

$$
\underset{\min}{w,b}\sum_{i=1}^N (1-y_i(wx_i+b))+\lambda\Vert w\Vert ^2
$$

上式相似于下式

$$
\frac{1}{m}\sum_{i=1}^{N}l(wx_i+by_i) + \Vert w\Vert ^2
$$

其中$l(wx_i+by_i)$是Hinge损失函数，$\Vert w\Vert ^2$可看做为正则化项。



### 6.2.7 **感知损失(perceptron loss)函数**

**感知损失函数**的标准形式如下：

![[公式]](https://www.zhihu.com/equation?tex=L%28y%2C+f%28x%29%29+%3D+max%280%2C+-f%28x%29%29++%5C%5C)

特点：

- 它是Hinge损失函数的一个变种，Hinge loss对判定边界附近的点(正确端)惩罚力度很高。而perceptron loss**只要样本的判定类别正确的话，它就满意，不管其判定边界的距离**。

- 它比Hinge loss简单，因为不是max-margin boundary，所以模**型的泛化能力没 hinge loss强**。





### 6.2.8 交叉熵损失函数

形式如下所示：
$$
L = -\frac{1}{n}\sum_x[ylna+(1-y)ln(1-a)]
$$
其中 $x$ 表示样本，$y$ 表示实际值，$a$ 表示输出值，$n$ 表示样本的总数。

将交叉熵看作代价函数的亮点原因：

1. 它是非负的，L > 0。可以看出：式子中的求和中的所有独⽴的项都是负数的，因为对数函数的定义域是 (0，1)，并且求和前⾯有⼀个负号，所以结果是非负。
2. 如果对于所有的训练输⼊ x，神经元实际的输出接近⽬标值，那么交叉熵将接近 0。实际输出和⽬标输出之间的差距越⼩，最终的交叉熵的值就越低了。（这里假设输出结果不是0，就是1，实际分类也是这样的）



特点如下：

- 本质上也是一种**对数似然函数**，可用于二分类和多分类任务中；
- 当预测输出和实际值大的时候，即误差大，损失 L 也越大，此时对模型的”惩罚“也越大，所以权重更新也快；而误差小的时候，则权重更新慢；
- 当使用sigmoid作为激活函数的时候，常用**交叉熵损失函数**而不用**均方误差损失函数**，因为它可以**完美解决平方损失函数权重更新过慢**的问题，具有“误差大的时候，权重更新快；误差小的时候，权重更新慢”的良好性质。
- 衡量的是概率分布的差异，即交叉熵是用来描述两个概率分布之间的差距，交叉熵越小，假设分布离真实分布越近，模型越好



**优点**：

在用梯度下降法做参数更新的时候，模型学习的速度取决于两个值：一、**学习率**；二、**偏导值**。其中，学习率是我们需要设置的超参数，所以我们重点关注偏导值。从上面的式子中，我们发现，偏导值的大小取决于 ![[公式]](https://www.zhihu.com/equation?tex=x_i) 和 ![[公式]](https://www.zhihu.com/equation?tex=%5B%5Csigma%28s%29-y%5D) ，我们重点关注后者，后者的大小值反映了我们模型的错误程度，该值越大，说明模型效果越差，但是该值越大同时也会使得偏导值越大，从而模型学习速度更快。所以，使用逻辑函数得到概率，并结合交叉熵当损失函数时，在模型效果差的时候学习速度比较快，在模型效果好的时候学习速度变慢。



**缺点**：

Softmax Loss的两个缺点：

1. 随着分类数目的增大，分类层的线性变化矩阵参数也随着增大；
2. 对于封闭集分类问题，学习到的特征是可分离的，但对于开放集人脸识别问题，所学特征却没有足够的区分性

对于人脸识别问题，首先人脸数目(对应分类数目)是很多的，而且会不断有新的人脸进来，不是一个封闭集分类问题。

另外，sigmoid(softmax)+cross-entropy loss 擅长于学习类间的信息，因为它采用了类间竞争机制，它只关心对于正确标签预测概率的准确性，忽略了其他非正确标签的差异，**导致学习到的特征比较散**。基于这个问题的优化有很多，比如对softmax进行改进，如L-Softmax、SM-Softmax、AM-Softmax等。





更多关于交叉熵损失函数，可以看这几篇文章：

- https://zhuanlan.zhihu.com/p/38241764
- https://zhuanlan.zhihu.com/p/35709485



------

# 7. 生成模型和判别模型的区别

## 生成模型

由数据学习联合概率密度分布P(X,Y)，然后求出条件概率分布P(Y|X)作为预测的模型，即生成模型：P(Y|X)= P(X,Y)/ P(X)（贝叶斯概率）。

基本思想是首先建立样本的联合概率概率密度模型P(X,Y)，然后再得到后验概率P(Y|X)，再利用它进行分类。

典型的生成模型有**朴素贝叶斯，隐马尔科夫模型**等



## 判别模型

由数据直接学习决策函数Y=f(X)或者条件概率分布P(Y|X)作为预测的模型，即判别模型。

基本思想是有限样本条件下建立判别函数，不考虑样本的产生模型，直接研究预测模型。

典型的判别模型包括**k近邻，感知级，决策树，支持向量机**等。

这些**模型的特点都是输入属性X可以直接得到后验概率P(Y|X)，**输出条件概率最大的作为最终的类别（对于二分类任务来说，实际得到一个score，当score大于threshold时则为正类，否则为负类）。



## 举例

判别式模型举例：要确定一个羊是山羊还是绵羊，用判别模型的方法是从历史数据中学习到模型，然后通过提取这只羊的特征来预测出这只羊是山羊的概率，是绵羊的概率。



生成式模型举例：利用生成模型是根据山羊的特征首先学习出一个山羊的模型，然后根据绵羊的特征学习出一个绵羊的模型，然后从这只羊中提取特征，放到山羊模型中看概率是多少，在放到绵羊模型中看概率是多少，哪个大就是哪个。



## 联系和区别

生成方法的特点：

- 生成方法学习联合概率密度分布P(X,Y)，所以就可以从统计的角度表示数据的分布情况，能够反映同类数据本身的相似度。但它不关心到底划分各类的那个分类边界在哪。
- 生成方法可以还原出联合概率分布P(Y,X)，而判别方法不能。
- **生成方法的学习收敛速度更快**，即当样本容量增加的时候，学到的模型可以更快的收敛于真实模型，当存在隐变量时，仍可以用生成方法学习。此时判别方法就不能用。

 

判别方法的特点：

- 判别方法直接学习的是决策函数Y=f(X)或者条件概率分布P(Y|X）
- **不能反映训练数据本身的特性**。但它寻找不同类别之间的最优分类面，反映的是异类数据之间的差异。
- 直接面对预测，**往往学习的准确率更高**。由于直接学习P(Y|X)或P(X)，可以对数据进行各种程度上的抽象、定义特征并使用特征，因此可以简化学习问题。



# 参考

1. 《深度学习》
2. 深度学习 500 问：https://github.com/scutan90/DeepLearning-500-questions
3. https://www.zhihu.com/question/358632429/answer/919562000
4. https://www.zhihu.com/question/68109802/answer/263503269
5. 《hands-on-ml-with-sklearn-and-tf》
6. Andrew Ng 在 Coursea 上的[机器学习课程](https://www.coursera.org/learn/machine-learning)



