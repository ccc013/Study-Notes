# 度量学习

ranking loss的目的是去预测输入样本之间的相对距离。这个任务经常也被称之为**度量学习**(metric learning)

介绍度量学习相关的方法，包括：

1. triplet loss
2. rank loss





## rank loss

参考：

- [一文理解Ranking Loss/Contrastive Loss/Margin Loss/Triplet Loss/Hinge Loss](https://blog.csdn.net/LoseInVain/article/details/103995962)



### 简介

相比其他的损失函数，比如交叉熵、均方差损失函数，他们的目标是学习如何预测标签，或者回归出一个数值，或者预测一组数值。rank loss 的目标则是**预测输入样本之间的相对距离**，其任务名称也被称为**度量学习**。

采用 rank loss 函数，需要一个衡量数据之前的相似度方法，通常用的是欧式距离或者余弦相似度，使用 rank loss 的过程通常如下：

1. 采用 CNN 对输入的数据，通常是两张图片或者三张图片，分别提取特征，并得到相应的 embedding；
2. 采用定义好的距离度量函数来度量 embedding 之间的相似度，通常是欧式距离或者余弦相似度；
3. 最后使用 rank loss 计算 loss，并通过反向传播更新网络参数，并重复这个过程，直到满足迭代终止条件（最大迭代次数或者 loss 比较稳定不再下降等）



### rank loss 的分类

随着对度量学习的研究，出现了越来越多不同的 rank loss，比如：

1. Contrastive Loss：输入是一对数据，比如正负样本；
2. Triplet Loss：输入是三元组，通常是包括 anchor 和正负样本；
3. **Hinge loss**：也被称之为**max-margin objective**。通常在分类任务中训练SVM的时候使用。他有着和SVM目标相似的表达式和目的：都是一直优化直到到达预定的边界为止。
4. Margin Loss





### 深度学习框架中的ranking loss层

#### Caffe

- Constrastive loss layer
- pycaffe triplet ranking loss layer

#### PyTorch

- CosineEmbeddingLoss
- MarginRankingLoss
- TripletMarginLoss

#### TensorFlow

- contrastive_loss
- triplet_semihard_loss











## Triplet Loss

参考：

- [为什么triplet loss有效？](https://bindog.github.io/blog/2019/10/23/why-triplet-loss-works/)
- [triplet loss 在深度学习中主要应用在什么地方？有什么明显的优势？](https://www.zhihu.com/question/62486208)
- [Triplet Network, Triplet Loss及其tensorflow实现](https://zhuanlan.zhihu.com/p/35560666)
- [triplet loss原理推导及变体](http://blog.rexking6.top/2018/04/07/triplet-loss%E5%8E%9F%E7%90%86%E6%8E%A8%E5%AF%BC%E5%8F%8A%E5%8F%98%E4%BD%93/)



### 简介

Triplet loss最早被用在人脸识别任务上，《FaceNet: A Unified Embedding for Face Recognition》 by Google。Google的研究人员提出了通过online triplet mining的方式训练处人脸的新向量表示。

Triplet loss 是度量学习（metric learning）中比较有代表性的一个办法，也是比较常用的一个方法，其基本思想是非常的简单明了，**即让同一个类别样本的特征向量尽可能靠近，不同类别样本的特征向量尽可能远离**，这里的特征向量是通过同一个网络模型提取得到的。

在triplet loss中，我们会选取一个三元组，如下图所示，首先从训练集中选取一个样本作为 Anchor，然后再随机选取一个与 Anchor 属于同一类别的样本作为 Positive，最后再从其他类别随机选取一个作为 Negative，这里将样本的 feature embedding 记为 x，那么一个基本的三元组triplet loss如下：
$$
L_{triplet} = max(d(x_a, x_p)-d(x_a, x_n)+m, 0)
$$
其中 $d(\cdot)$ 表示两个样本的距离，m 是间隔 margin，上述公式就是要求负样本到 Anchor 的距离要比正样本到 Anchor 的距离大 m，也就是说，**如果 m 越大，不同类别之间的可区分性就越强，当然训练难度也越大**。当然也可以让 m=0，这样条件就放松很多，但是就体现不出来 triplet loss 的优势。

<img src="https://gitee.com/lcai013/image_cdn/raw/master/notes_images/triplet_loss_fig4.png" style="zoom:75%;" />



**triplet loss的优势在于细节区分**，即当两个输入相似时，**triplet loss能够更好地对细节进行建模，相当于加入了两个输入差异性差异的度量，学习到输入的更好表示**，从而在上述两个任务中有出色的表现。

当然，triplet loss的缺点在于其**训练过程不稳定，收敛速度慢，有时不收敛**。很多情况下不会单独使用 Triplet loss，而是和 softmax loss 等方法结合使用，以稳定训练过程。



Triplet loss 网络结构如下所示：输入的图片是经过同一个网络，分别提取到特征向量，然后计算 Triplet loss；

<img src="https://gitee.com/lcai013/image_cdn/raw/master/notes_images/triplet_loss_fig2.jpeg" style="zoom:67%;"/>

### Triplet loss 梯度推导

triplet loss 的目标函数为：
$$
L = \sum_i^N [||f(x_i^a)-f(x_i^p))||^2_2 - ||f(x_i^a)-f(x_i^n)||^2_2+m]_+
$$
这里距离用欧式距离度量，+表示 [] 内的值大于零的时候，取该值为损失，小于零的时候，损失为零。

由目标函数可以看出：

- 当 $x_i^a$ 与 $x_i^n$ 之间的距离小于 $x_i^a$ 与 $x_i^p$ 之间的距离加 m，则 [] 内的数值会大于 0，也就是产生了损失；
- 当 $x_i^a$ 与 $x_i^n$ 之间的距离大于等于 $x_i^a$ 与 $x_i^p$ 之间的距离加 m，损失是 0

当第 i 个 triplet loss 大于 0 的时候，对于上述公式，梯度计算如下：

<img src="https://gitee.com/lcai013/image_cdn/raw/master/notes_images/triplet_loss_fig5.png" style="zoom:80%;" />



### Triplet mining

**基于triplet loss的定义，可以将triplet(三元组)分为三类**：

- **easy triplets(简单三元组)**: triplet对应的损失为0的三元组，形式化定义为 $d(x_a,x_n)>d(x_a,x_p)+margin$。

- **hard triplets（困难三元组）**: negative example 与 anchor距离小于anchor与positive example的距离，形式化定义为$d(x_a,x_n)<d(x_a,x_p)$。

- **semi-hard triplets（一般三元组）**: negative example 与anchor距离大于anchor与positive example的距离，但还不至于使得loss为0，即 $d(x_a,x_p)<d(x_a,x_n)<d(x_a,x_p)+margin$。

上述三种概念都是基于 negative example与anchor和positive距离定义的。类似的，可以根据上述定义将negative examples分为3类：

- hard negatives,
- easy negatives,
- semi-hard negatives。


如下图所示，这个图构建了编码空间中三种 negative examples与anchor和positive example之间的距离关系。

<img src="https://gitee.com/lcai013/image_cdn/raw/master/notes_images/triplet_loss_fig.png" style="zoom:85%;" />

通过这些分析，可以知道三类负样本中，easy negatives 比较容易识别，没必要构建太多这类样本，否则会降低训练效率；而 hard negatives 则非常难识别，会提高训练难度，降低训练效果，所以挑选 triplet 是非常重要的，即需要合适的采样策略。

这里又分为离线和在线的 triplet mining

#### Offline triplet mining

离线方式的做法就是先将所有训练数据都输入到网络中，然后提取 embedding，计算负样本和 anchor 和正样本的距离，根据这个距离判断负样本属于哪类负样本。离线方式仅选择 semi-hard 或者 hard triplets。

不过这个方式不够高效，因为一开始需要将所有数据都输入到网络中，并且可能每过几个 epoch，还要重新对负样本进行分类

#### online triplet mining

online triplet mining 方法的motivation比较简单，将 B 张图片（一个batch）喂给神经网络，得到B张图片的embedding，将triplet的组合一共最多$B^3$个triplets，其中包含很多没用的triplet（比如，三个negative examples和三个positive examples，这种称作invalid triplets）。哪些是valid triplets呢？假设一个triplet$(B_i,B_j,B_k)$，如果样本i和j有相同的label且不是同一个样本，而样本k具有不同的label，则称其为valid triplet。

假设一个batch的数据包含P*K张人脸，P个人，每人K张图片。

针对 valid triplet的“挑选”，有以下两个策略（来自论文[[1703.07737\] In Defense of the Triplet Loss for Person Re-Identification](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1703.07737))：

- **batch all**: 计算所有的valid triplet，对 hard 和 semi-hard triplets上的loss进行平均。
  - 不考虑easy triplets，因为easy triplets的损失为0，平均会把整体损失缩小
  - 将会产生 PK(K-1)(PK-K) 个triplet，即 PK 个anchor，对于每个anchor有 k-1 个可能的positive example，PK-K个可能的negative examples
- **batch hard**: 对于每一个anchor，**选择hardest positive example(距离anchor最大的positive example)和hardest negative(距离anchor最小的negative example)**，由此产生PK个triplet，这些triplet是最难分的

<img src="https://gitee.com/lcai013/image_cdn/raw/master/notes_images/triplet_loss_fig3.jpeg" alt="Online triplet loss" style="zoom:80%;" />

论文[《In Defense of the Triplet Loss for Person Re-Identification》]([[1703.07737\] In Defense of the Triplet Loss for Person Re-Identification](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1703.07737))实验结果表明，batch hard的表现是最好的。





### 缺点

triplet loss 的缺点有这几个：

- 训练过程不稳定：softmax loss 中每个 batch 的 loss 都能够兼顾全局信息，并进行权重更新，这一点能够保证整个训练过程相对平滑稳定；而 triplet loss 中每个 batch 所涉及和更新的信息是非常局限的，即只包含 2 个类别，**如果不能设计合理的采样和训练策略，容易出现的一种情况是某个类别的embedding分布不稳定、出现突变和跃迁，导致训练反复、难以收敛**。
- 收敛速度慢
- 对学习率和超参数非常敏感，需要精心调参





### 应用

适合应用在细粒度分类，比如人脸识别相关的任务中，这类任务因为类别数量太多，如果用 softmax loss，那边输出的特征维度（比如 2048）相比于有上万甚至更多维度的类别数量是太少了。





### 代码实现

#### Tensorflow

##### offline triplets

```python
anchor_output = ...    # shape [None, 128]
positive_output = ...  # shape [None, 128]
negative_output = ...  # shape [None, 128]

d_pos = tf.reduce_sum(tf.square(anchor_output - positive_output), 1)
d_neg = tf.reduce_sum(tf.square(anchor_output - negative_output), 1)

loss = tf.maximum(0.0, margin + d_pos - d_neg)
loss = tf.reduce_mean(loss)
```



##### online triplets

**batch all的实现方式**

```python
def batch_all_triplet_loss(labels, embeddings, margin, squared=False):
"""Build the triplet loss over a batch of embeddings.

We generate all the valid triplets and average the loss over the positive ones.

Args:
   labels: labels of the batch, of size (batch_size,)
   embeddings: tensor of shape (batch_size, embed_dim)
   margin: margin for triplet loss
   squared: Boolean. If true, output is the pairwise squared euclidean distance matrix.
            If false, output is the pairwise euclidean distance matrix.

Returns:
   triplet_loss: scalar tensor containing the triplet loss
"""
    # Get the pairwise distance matrix
    pairwise_dist = _pairwise_distances(embeddings, squared=squared)

    anchor_positive_dist = tf.expand_dims(pairwise_dist, 2)
    anchor_negative_dist = tf.expand_dims(pairwise_dist, 1)

    # Compute a 3D tensor of size (batch_size, batch_size, batch_size)
    # triplet_loss[i, j, k] will contain the triplet loss of anchor=i, positive=j, negative=k
    # Uses broadcasting where the 1st argument has shape (batch_size, batch_size, 1)
    # and the 2nd (batch_size, 1, batch_size)
    triplet_loss = anchor_positive_dist - anchor_negative_dist + margin

    # Put to zero the invalid triplets
    # (where label(a) != label(p) or label(n) == label(a) or a == p)
    mask = _get_triplet_mask(labels)
    mask = tf.to_float(mask)
    triplet_loss = tf.multiply(mask, triplet_loss)

    # Remove negative losses (i.e. the easy triplets)
    triplet_loss = tf.maximum(triplet_loss, 0.0)

    # Count number of positive triplets (where triplet_loss > 0)
    valid_triplets = tf.to_float(tf.greater(triplet_loss, 1e-16))
    num_positive_triplets = tf.reduce_sum(valid_triplets)
    num_valid_triplets = tf.reduce_sum(mask)
    fraction_positive_triplets = num_positive_triplets / (num_valid_triplets + 1e-16)

    # Get final mean triplet loss over the positive valid triplets
    triplet_loss = tf.reduce_sum(triplet_loss) / (num_positive_triplets + 1e-16)

    return triplet_loss, fraction_positive_triplets
```

**batch hard的实现方式**

```python
def batch_hard_triplet_loss(labels, embeddings, margin, squared=False):
"""Build the triplet loss over a batch of embeddings.

For each anchor, we get the hardest positive and hardest negative to form a triplet.

Args:
   labels: labels of the batch, of size (batch_size,)
   embeddings: tensor of shape (batch_size, embed_dim)
   margin: margin for triplet loss
   squared: Boolean. If true, output is the pairwise squared euclidean distance matrix.
            If false, output is the pairwise euclidean distance matrix.

Returns:
   triplet_loss: scalar tensor containing the triplet loss
"""
    # Get the pairwise distance matrix
    pairwise_dist = _pairwise_distances(embeddings, squared=squared)

    # For each anchor, get the hardest positive
    # First, we need to get a mask for every valid positive (they should have same label)
    mask_anchor_positive = _get_anchor_positive_triplet_mask(labels)
    mask_anchor_positive = tf.to_float(mask_anchor_positive)

    # We put to 0 any element where (a, p) is not valid (valid if a != p and label(a) == label(p))
    anchor_positive_dist = tf.multiply(mask_anchor_positive, pairwise_dist)

    # shape (batch_size, 1)
    hardest_positive_dist = tf.reduce_max(anchor_positive_dist, axis=1, keepdims=True)

    # For each anchor, get the hardest negative
    # First, we need to get a mask for every valid negative (they should have different labels)
    mask_anchor_negative = _get_anchor_negative_triplet_mask(labels)
    mask_anchor_negative = tf.to_float(mask_anchor_negative)

    # We add the maximum value in each row to the invalid negatives (label(a) == label(n))
    max_anchor_negative_dist = tf.reduce_max(pairwise_dist, axis=1, keepdims=True)
    anchor_negative_dist = pairwise_dist + max_anchor_negative_dist * (1.0 - mask_anchor_negative)

    # shape (batch_size,)
    hardest_negative_dist = tf.reduce_min(anchor_negative_dist, axis=1, keepdims=True)

    # Combine biggest d(a, p) and smallest d(a, n) into final triplet loss
    triplet_loss = tf.maximum(hardest_positive_dist - hardest_negative_dist + margin, 0.0)

    # Get final mean triplet loss
    triplet_loss = tf.reduce_mean(triplet_loss)

    return triplet_loss
```





### Triplet loss 的变体

triplet loss 也有几种改进的变体：

- Beyond Triplet Loss

- In Defense of the Triplet Loss

- Improved Triplet Loss

- Lifted Structured Loss



#### Beyond Triplet Loss

一篇讲Person Re-ID的论文，来自CVPR2017，改进了Triplet Loss。

文章链接： [《Beyond triplet loss: a deep quadruplet network for person re-identification》](http://cn.arxiv.org/abs/1704.01719?context=cs)

<img src="https://gitee.com/lcai013/image_cdn/raw/master/notes_images/triplet_loss_fig6.png" style="zoom:75%;" />

文章的出发点就在上面这张图。 如上图a，传统的triplet Loss可能在test集上泛化效果一般，**主要是因为类内方差依然比较大**。文章对此增加了新的约束，**用于减小类内方差和增加类间方差**。

即，新的Loss不仅要求 B1B3<B1A3， 同时要求 C1C2<B1A3



#### In Defense of the Triplet Loss





#### Improved Triplet Loss





#### Lifted Structured Loss